name: Extract PDF batch

# ── Triggers ──────────────────────────────────────────────────────────────────
# Manual trigger only — prevents accidental or recursive runs.
# Run via: gh workflow run extract.yml -f keys="KEY1 KEY2 KEY3"
# Or via GitHub UI: Actions → Extract PDF batch → Run workflow
on:
  workflow_dispatch:
    inputs:
      keys:
        description: "Space-separated doc keys to process (leave blank for all unextracted)"
        required: false
        default: ""
      use_vision:
        description: "Enable Google Vision OCR fallback (costs ~$1.50/1000 pages)"
        type: boolean
        required: false
        default: false
      workers:
        description: "Parallel worker threads (keep at 1 for large scanned PDFs — memory limits)"
        required: false
        default: "1"
      run_layout:
        description: "Also run Heron layout enrichment (05c) after extraction"
        type: boolean
        required: false
        default: true

# ── Permissions ───────────────────────────────────────────────────────────────
permissions:
  contents: write    # needed to commit extracted results back

jobs:
  extract:
    runs-on: ubuntu-latest
    timeout-minutes: 360   # 6 hours — generous for large batches

    steps:
      # ── Checkout (with LFS to pull PDFs) ────────────────────────────────────
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          lfs: true
          fetch-depth: 1
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull LFS objects (PDFs)
        run: |
          git lfs pull --include="data/pdfs/**"
          echo "PDFs available:"
          find data/pdfs -name "*.pdf" | wc -l

      # ── Python setup ─────────────────────────────────────────────────────────
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          # Install PyTorch CPU-only first (much smaller than full GPU build)
          pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
          # Then install everything else
          pip install -r requirements.txt

      # ── Tesseract ─────────────────────────────────────────────────────────────
      - name: Install Tesseract OCR
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y -qq \
            tesseract-ocr \
            tesseract-ocr-eng \
            tesseract-ocr-ara \
            tesseract-ocr-fas \
            tesseract-ocr-tur \
            tesseract-ocr-deu \
            tesseract-ocr-fra
          tesseract --version

      # ── Google Vision credentials (optional) ─────────────────────────────────
      - name: Write Vision credentials
        if: ${{ inputs.use_vision }}
        run: |
          echo '${{ secrets.GOOGLE_CREDENTIALS_JSON }}' > /tmp/google-credentials.json
          echo "GOOGLE_APPLICATION_CREDENTIALS=/tmp/google-credentials.json" >> $GITHUB_ENV
        # Requires a repo secret: GOOGLE_CREDENTIALS_JSON
        # containing the service account JSON as a single-line string

      # ── Set up .env for the pipeline ─────────────────────────────────────────
      - name: Create .env
        run: |
          cat > .env << EOF
          ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}
          COLLECTION_NAME=Islamic Cartography
          EOF

      # ── Run extraction (05b) — one process per key for memory isolation ────────
      - name: Run extraction
        run: |
          set +e   # don't abort on segfault — we handle failures per-key

          VISION_FLAG=""
          if [ "${{ inputs.use_vision }}" = "true" ]; then
            VISION_FLAG="--vision"
          fi

          # Build list of keys to process
          if [ -n "${{ inputs.keys }}" ]; then
            KEYS="${{ inputs.keys }}"
          else
            # Auto-discover unextracted keys from inventory
            KEYS=$(python3 -c "
          import json
          inv = json.load(open('data/inventory.json'))
          keys = [i['key'] for i in inv if not i.get('extracted') and i.get('pdf_path')]
          print(' '.join(keys))
          ")
          fi

          echo "Keys to process: $KEYS"
          FAILED=""

          # Process each key in its own subprocess — full memory reset between docs
          for KEY in $KEYS; do
            echo ""
            echo "════════════════════════════════════════"
            echo "Processing: $KEY"
            echo "════════════════════════════════════════"
            python scripts/05b_extract_robust.py \
              --workers 1 \
              --keys "$KEY" \
              $VISION_FLAG
            EXIT=$?
            if [ $EXIT -ne 0 ]; then
              echo "⚠ $KEY failed (exit $EXIT) — continuing with next doc"
              FAILED="$FAILED $KEY"
            fi
          done

          echo ""
          echo "All keys attempted."
          [ -n "$FAILED" ] && echo "Failed keys:$FAILED" || echo "All keys succeeded."
          exit 0   # never fail the step — results are logged above

      # ── Run layout enrichment (05c) via Modal T4 GPU ────────────────────────
      - name: Run Heron layout enrichment (Modal GPU)
        if: ${{ inputs.run_layout }}
        env:
          MODAL_TOKEN_ID: ${{ secrets.MODAL_TOKEN_ID }}
          MODAL_TOKEN_SECRET: ${{ secrets.MODAL_TOKEN_SECRET }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Fail loudly if Modal credentials not configured
          if [ -z "$MODAL_TOKEN_ID" ] || [ -z "$MODAL_TOKEN_SECRET" ]; then
            echo "⚠ MODAL_TOKEN_ID / MODAL_TOKEN_SECRET not set in repo secrets."
            echo "  Add them at: Settings → Secrets → Actions"
            echo "  Get tokens at: https://modal.com/settings"
            exit 1
          fi

          pip install modal --quiet

          # Build list of keys that have page_texts.json (i.e. 05b succeeded)
          if [ -n "${{ inputs.keys }}" ]; then
            RAW_KEYS="${{ inputs.keys }}"
          else
            RAW_KEYS=$(python3 -c "
          import json
          inv = json.load(open('data/inventory.json'))
          keys = [i['key'] for i in inv if i.get('extracted')]
          print(' '.join(keys))
          ")
          fi

          KEYS=""
          for KEY in $RAW_KEYS; do
            if [ -f "data/texts/$KEY/page_texts.json" ]; then
              KEYS="$KEYS $KEY"
            else
              echo "⏭ Skipping $KEY — no page_texts.json (05b may have failed)"
            fi
          done
          KEYS=$(echo $KEYS | xargs)   # trim leading/trailing whitespace

          if [ -z "$KEYS" ]; then
            echo "No keys to enrich — skipping Modal run."
            exit 0
          fi

          echo "Dispatching Heron to Modal T4 GPU for keys: $KEYS"
          echo "(Modal will clone the repo, run Heron, commit results, and push back)"
          modal run scripts/modal_heron.py --keys "$KEYS"

      # ── Commit extraction results immediately (before slow Heron step) ─────────
      - name: Commit extraction results
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          python scripts/00_update_inventory_flags.py
          git add data/texts/ data/inventory.json

          if git diff --staged --quiet; then
            echo "Nothing new to commit from extraction."
          else
            CHANGED=$(git diff --staged --name-only | grep page_texts.json | wc -l)
            git commit -m "extract(05b): ${CHANGED} doc(s) [skip ci]

          Keys: ${{ inputs.keys || 'all-unextracted' }}
          Vision: ${{ inputs.use_vision }}
          Run: ${{ github.run_id }}"
            git pull --rebase origin main   # avoid reject if commits landed during extraction
            git push
            echo "✓ Extraction results committed for ${CHANGED} doc(s)."
          fi

      # ── Commit layout results after Heron ────────────────────────────────────
      # Modal already commits+pushes from inside its container, so this step is
      # normally a no-op.  It acts as a safety net if Modal ran without a token.
      - name: Commit layout results (fallback)
        if: ${{ inputs.run_layout }}
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/texts/

          if git diff --staged --quiet; then
            echo "Nothing new to commit from layout enrichment."
          else
            CHANGED=$(git diff --staged --name-only | grep layout_elements.json | wc -l)
            git commit -m "layout(05c): ${CHANGED} doc(s) enriched [skip ci]

          Keys: ${{ inputs.keys || 'all-unextracted' }}
          Run: ${{ github.run_id }}"
            git push
            echo "✓ Layout results committed for ${CHANGED} doc(s)."
          fi

      # ── Summary ───────────────────────────────────────────────────────────────
      - name: Pipeline summary
        if: always()
        run: |
          echo "=== Extraction complete ==="
          python -c "
          import json, os
          p = 'data/pipeline_status.json'
          if os.path.exists(p):
              s = json.load(open(p))
              docs = s.get('docs', {})
              ok  = sum(1 for d in docs.values() if d.get('state') == 'ok')
              err = sum(1 for d in docs.values() if d.get('state') == 'error')
              print(f'  OK: {ok}   Errors: {err}')
              for k, v in docs.items():
                  if v.get('state') == 'error':
                      print(f'  ERROR {k}: {v.get(\"error\",\"?\")[:80]}')
          else:
              print('  No status file found.')
          " 2>/dev/null || true
