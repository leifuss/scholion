name: Extract PDF batch

# ── Triggers ──────────────────────────────────────────────────────────────────
# Manual trigger only — prevents accidental or recursive runs.
# Run via: gh workflow run extract.yml -f keys="KEY1 KEY2 KEY3"
# Or via GitHub UI: Actions → Extract PDF batch → Run workflow
on:
  workflow_dispatch:
    inputs:
      collection_slug:
        description: "Collection slug (from data/collections.json) — leave blank for root collection"
        required: false
        default: ""
      keys:
        description: "Space-separated doc keys to process (leave blank for all unextracted)"
        required: false
        default: ""
      workers:
        description: "Parallel worker threads (keep at 1 for large scanned PDFs — memory limits)"
        required: false
        default: "1"
      run_layout:
        description: "Also run Heron layout enrichment (05c) after extraction"
        type: boolean
        required: false
        default: true

# ── Permissions ───────────────────────────────────────────────────────────────
permissions:
  contents: write    # needed to commit extracted results back

jobs:
  extract:
    runs-on: ubuntu-latest
    timeout-minutes: 360   # 6 hours — generous for large batches

    steps:
      # ── Checkout ───────────────────────────────────────────────────────────
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          token: ${{ secrets.GITHUB_TOKEN }}

      # ── Python setup ─────────────────────────────────────────────────────────
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          # Install PyTorch CPU-only first (much smaller than full GPU build)
          pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
          # Then install everything else
          pip install -r requirements.txt

      # ── Tesseract ─────────────────────────────────────────────────────────────
      - name: Install Tesseract OCR
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y -qq \
            tesseract-ocr \
            tesseract-ocr-eng \
            tesseract-ocr-ara \
            tesseract-ocr-fas \
            tesseract-ocr-tur \
            tesseract-ocr-deu \
            tesseract-ocr-fra
          tesseract --version

      # ── Set up .env for the pipeline ─────────────────────────────────────────
      - name: Create .env
        run: |
          python3 - << 'PYEOF'
          import json, os
          from pathlib import Path

          root = Path('data/corpus_config.json')
          c = json.load(open(root))
          z = c.get('source', {}).get('zotero_api', {})

          slug = os.environ.get('COLLECTION_SLUG', '')
          if slug:
              try:
                  colls = json.load(open('data/collections.json'))
                  coll = next(
                      (x for x in colls.get('collections', []) if x['slug'] == slug),
                      None,
                  )
                  if coll:
                      coll_src = coll.get('source', {})
                      path = coll.get('path', slug)
                      coll_cfg_path = (
                          Path('data/corpus_config.json') if path == '.'
                          else Path('data') / path / 'corpus_config.json'
                      )
                      coll_cfg_src = {}
                      if coll_cfg_path.exists():
                          coll_cfg = json.load(open(coll_cfg_path))
                          coll_cfg_src = (
                              coll_cfg.get('source', {}).get('zotero_api', {})
                              or coll_cfg.get('source', {})
                          )
                      for k in ('library_id', 'library_type', 'collection_name', 'collection_key'):
                          val = coll_cfg_src.get(k) or coll_src.get(k)
                          if val:
                              z[k] = val
              except Exception as e:
                  print(f'Warning: could not load collection config: {e}')

          with open('.env', 'w') as f:
              f.write(f"ZOTERO_API_KEY={os.environ.get('ZOTERO_API_KEY', '')}\n")
              f.write(f"ZOTERO_LIBRARY_ID={z.get('library_id') or ''}\n")
              f.write(f"ZOTERO_LIBRARY_TYPE={z.get('library_type', 'user')}\n")
              col = z.get('collection_name') or ''
              f.write(f"COLLECTION_NAME={col}\n")
              f.write(f"GEMINI_API_KEY={os.environ.get('GEMINI_API_KEY', '')}\n")
              f.write(f"ANTHROPIC_API_KEY={os.environ.get('ANTHROPIC_API_KEY', '')}\n")

          print(f"ZOTERO_LIBRARY_ID={z.get('library_id') or '(unset)'}")
          print(f"ZOTERO_LIBRARY_TYPE={z.get('library_type', 'user')}")
          print(f"COLLECTION_NAME={z.get('collection_name') or ''}")
          PYEOF
        env:
          ZOTERO_API_KEY: ${{ secrets.ZOTERO_API_KEY }}
          COLLECTION_SLUG: ${{ inputs.collection_slug }}

      # ── Fetch PDFs from Zotero cloud ─────────────────────────────────────────
      - name: Fetch PDFs from Zotero
        run: |
          SLUG_FLAG=""
          [ -n "${{ inputs.collection_slug }}" ] && SLUG_FLAG="--collection-slug ${{ inputs.collection_slug }}"
          if [ -n "${{ inputs.keys }}" ]; then
            python scripts/00_stage_pdfs.py --keys ${{ inputs.keys }} $SLUG_FLAG
          else
            python scripts/00_stage_pdfs.py $SLUG_FLAG
          fi
          echo "PDFs available:"
          find data/pdfs -name "*.pdf" 2>/dev/null | wc -l

      # ── Run extraction (05b) — one process per key for memory isolation ────────
      - name: Run extraction
        run: |
          set +e   # don't abort on segfault — we handle failures per-key

          SLUG="${{ inputs.collection_slug }}"
          SLUG_FLAG=""
          [ -n "$SLUG" ] && SLUG_FLAG="--collection-slug $SLUG"

          # Resolve inventory path for key discovery
          if [ -n "$SLUG" ]; then
            INV_FILE=$(python3 -c "
          import json
          data = json.load(open('data/collections.json'))
          for c in data.get('collections', []):
              if c['slug'] == '$SLUG':
                  p = c.get('path', '$SLUG')
                  print('data/inventory.json' if p == '.' else f'data/{p}/inventory.json')
                  break
          ")
          else
            INV_FILE="data/inventory.json"
          fi
          echo "Inventory: $INV_FILE"

          # Build list of keys to process
          if [ -n "${{ inputs.keys }}" ]; then
            KEYS="${{ inputs.keys }}"
          else
            # Auto-discover unextracted keys from collection inventory
            KEYS=$(python3 -c "
          import json
          inv = json.load(open('$INV_FILE'))
          keys = [i['key'] for i in inv if not i.get('extracted') and i.get('pdf_path')]
          print(' '.join(keys))
          ")
          fi

          echo "Keys to process: $KEYS"
          FAILED=""

          # Process each key in its own subprocess — full memory reset between docs
          for KEY in $KEYS; do
            echo ""
            echo "════════════════════════════════════════"
            echo "Processing: $KEY"
            echo "════════════════════════════════════════"
            python scripts/05b_extract_robust.py \
              --workers 1 \
              --keys "$KEY" \
              $SLUG_FLAG
            EXIT=$?
            if [ $EXIT -ne 0 ]; then
              echo "⚠ $KEY failed (exit $EXIT) — continuing with next doc"
              FAILED="$FAILED $KEY"
            fi
          done

          echo ""
          echo "All keys attempted."
          [ -n "$FAILED" ] && echo "Failed keys:$FAILED" || echo "All keys succeeded."
          exit 0   # never fail the step — results are logged above

      # ── Commit extraction results BEFORE Heron so Modal can find page_texts.json
      - name: Commit extraction results
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          SLUG="${{ inputs.collection_slug }}"
          SLUG_FLAG=""
          [ -n "$SLUG" ] && SLUG_FLAG="--collection-slug $SLUG"

          python scripts/00_update_inventory_flags.py $SLUG_FLAG

          # Stage texts and inventory for the correct collection
          if [ -n "$SLUG" ]; then
            COLL_PATH=$(python3 -c "
          import json
          data = json.load(open('data/collections.json'))
          for c in data.get('collections', []):
              if c['slug'] == '$SLUG':
                  p = c.get('path', '$SLUG')
                  print('.' if p == '.' else f'data/{p}')
                  break
          ")
            git add "${COLL_PATH}/texts/" "${COLL_PATH}/inventory.json" 2>/dev/null || true
          else
            git add data/texts/ data/inventory.json
          fi

          if git diff --staged --quiet; then
            echo "Nothing new to commit from extraction."
          else
            CHANGED=$(git diff --staged --name-only | grep page_texts.json | wc -l)
            git commit -m "extract(05b): ${CHANGED} doc(s) [skip ci]

          Collection: ${{ inputs.collection_slug || 'root' }}
          Keys: ${{ inputs.keys || 'all-unextracted' }}
          Run: ${{ github.run_id }}"
            git pull --rebase origin main   # avoid reject if commits landed during extraction
            git push
            echo "Extraction results committed for ${CHANGED} doc(s)."
          fi

      # ── Run layout enrichment (05c) via Modal T4 GPU ────────────────────────
      - name: Run Heron layout enrichment (Modal GPU)
        if: ${{ inputs.run_layout }}
        env:
          MODAL_TOKEN_ID: ${{ secrets.MODAL_TOKEN_ID }}
          MODAL_TOKEN_SECRET: ${{ secrets.MODAL_TOKEN_SECRET }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Fail loudly if Modal credentials not configured
          if [ -z "$MODAL_TOKEN_ID" ] || [ -z "$MODAL_TOKEN_SECRET" ]; then
            echo "MODAL_TOKEN_ID / MODAL_TOKEN_SECRET not set in repo secrets."
            echo "  Add them at: Settings → Secrets → Actions"
            echo "  Get tokens at: https://modal.com/settings"
            exit 1
          fi

          pip install modal --quiet

          # Resolve inventory and texts paths for this collection
          SLUG="${{ inputs.collection_slug }}"
          if [ -n "$SLUG" ]; then
            COLL_PATH=$(python3 -c "
          import json
          data = json.load(open('data/collections.json'))
          for c in data.get('collections', []):
              if c['slug'] == '$SLUG':
                  p = c.get('path', '$SLUG')
                  print('.' if p == '.' else f'data/{p}')
                  break
          ")
            INV_FILE="${COLL_PATH}/inventory.json"
            TEXTS_DIR="${COLL_PATH}/texts"
          else
            INV_FILE="data/inventory.json"
            TEXTS_DIR="data/texts"
          fi

          # Build list of keys that have page_texts.json (i.e. 05b succeeded)
          if [ -n "${{ inputs.keys }}" ]; then
            RAW_KEYS="${{ inputs.keys }}"
          else
            RAW_KEYS=$(python3 -c "
          import json
          inv = json.load(open('$INV_FILE'))
          keys = [i['key'] for i in inv if i.get('extracted')]
          print(' '.join(keys))
          ")
          fi

          KEYS=""
          for KEY in $RAW_KEYS; do
            if [ -f "${TEXTS_DIR}/$KEY/page_texts.json" ]; then
              KEYS="$KEYS $KEY"
            else
              echo "Skipping $KEY — no page_texts.json (05b may have failed)"
            fi
          done
          KEYS=$(echo $KEYS | xargs)   # trim leading/trailing whitespace

          if [ -z "$KEYS" ]; then
            echo "No keys to enrich — skipping Modal run."
            exit 0
          fi

          echo "Dispatching Heron to Modal T4 GPU for keys: $KEYS"
          echo "(Modal will clone the repo, run Heron, commit results, and push back)"
          modal run scripts/modal_heron.py --keys "$KEYS"

      # ── Commit layout results after Heron ────────────────────────────────────
      # Modal already commits+pushes from inside its container, so this step is
      # normally a no-op.  It acts as a safety net if Modal ran without a token.
      - name: Commit layout results (fallback)
        if: ${{ inputs.run_layout }}
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/texts/

          if git diff --staged --quiet; then
            echo "Nothing new to commit from layout enrichment."
          else
            CHANGED=$(git diff --staged --name-only | grep layout_elements.json | wc -l)
            git commit -m "layout(05c): ${CHANGED} doc(s) enriched [skip ci]

          Keys: ${{ inputs.keys || 'all-unextracted' }}
          Run: ${{ github.run_id }}"
            git push
            echo "Layout results committed for ${CHANGED} doc(s)."
          fi

      # ── Summary ───────────────────────────────────────────────────────────────
      - name: Pipeline summary
        if: always()
        run: |
          echo "=== Extraction complete ==="
          python -c "
          import json, os
          p = 'data/pipeline_status.json'
          if os.path.exists(p):
              s = json.load(open(p))
              docs = s.get('docs', {})
              ok  = sum(1 for d in docs.values() if d.get('state') == 'ok')
              err = sum(1 for d in docs.values() if d.get('state') == 'error')
              print(f'  OK: {ok}   Errors: {err}')
              for k, v in docs.items():
                  if v.get('state') == 'error':
                      print(f'  ERROR {k}: {v.get(\"error\",\"?\")[:80]}')
          else:
              print('  No status file found.')
          " 2>/dev/null || true
