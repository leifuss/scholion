#!/usr/bin/env python3
"""
Inventory all Zotero items and write data/inventory.json.

For each item:
  - PDF status: stored / url_only / no_attachment
  - Doc type:   embedded / scanned / unknown
  - Language detection from text sample
  - Cross-referenced with extraction results if available

Outputs:
  data/inventory.json   – raw inventory data
  (dashboard.html and explore.html are now static files that fetch
   inventory.json at runtime — no regeneration needed.)

Usage:
    python scripts/03_inventory.py
    python scripts/03_inventory.py --output data/inventory.json
    python scripts/03_inventory.py --no-classify   # skip PDF classification (fast mode)
"""
import sys
import json
import re
import argparse
from pathlib import Path


# ── HTML helper (for Zotero note content) ─────────────────────────────────────

def _strip_html(html: str) -> str:
    """Remove HTML tags and decode common entities from Zotero note HTML."""
    text = re.sub(r'<[^>]+>', ' ', html or '')
    for ent, ch in [('&amp;', '&'), ('&lt;', '<'), ('&gt;', '>'),
                    ('&nbsp;', ' '), ('&#160;', ' '), ('&quot;', '"'), ('&#39;', "'")]:
        text = text.replace(ent, ch)
    return re.sub(r'\s+', ' ', text).strip()

_ROOT = Path(__file__).parent.parent
_SRC  = str(_ROOT / 'src')
sys.path.insert(0, _SRC)

from dotenv import load_dotenv
load_dotenv()

from zotero_client import ZoteroLibrary

# ── PDF classification ─────────────────────────────────────────────────────────
try:
    import pypdfium2 as pdfium
    _PDFIUM = True
except ImportError:
    _PDFIUM = False

try:
    from langdetect import detect, LangDetectException
    _LANGDETECT = True
except ImportError:
    _LANGDETECT = False

# Avg chars/page threshold below which we call a PDF "scanned"
_SCANNED_THRESHOLD = 50


def classify_pdf(path: Path) -> dict:
    """
    Classify a PDF as embedded-font or scanned, and detect language.
    Samples up to the first 5 pages only — fast enough for 300+ items.
    """
    result = {
        'page_count':    None,
        'doc_type':      'unknown',   # embedded | scanned | unknown
        'avg_chars_page': None,
        'language':      None,
        'lang_sample':   None,
    }

    if not _PDFIUM:
        return result

    try:
        doc = pdfium.PdfDocument(str(path))
        n   = len(doc)
        result['page_count'] = n

        # Sample first 3 + last 3 pages (deduped). Bilingual critical editions
        # often have Arabic at the physical back of the book, Western commentary
        # at the front — so we need both ends to detect all languages present.
        head = list(range(min(3, n)))
        tail = list(range(max(0, n - 3), n))
        sample_indices = list(dict.fromkeys(head + tail))  # preserve order, no dups

        texts       = []
        total_chars = 0

        for i in sample_indices:
            page     = doc[i]
            textpage = page.get_textpage()
            text     = textpage.get_text_range()
            total_chars += len(text)
            texts.append(text)

        # Use first-3 pages only for embedded/scanned classification
        first_chars = sum(len(doc[i].get_textpage().get_text_range()) for i in head)
        avg = first_chars / len(head) if head else 0
        result['avg_chars_page'] = round(avg, 1)
        result['doc_type'] = 'scanned' if avg < _SCANNED_THRESHOLD else 'embedded'

        sample_text = ' '.join(texts)[:4000]
        result['lang_sample'] = sample_text[:200].strip()

        if _LANGDETECT and sample_text.strip():
            try:
                result['language'] = detect(sample_text)
            except LangDetectException:
                result['language'] = 'unknown'

    except Exception as e:
        result['doc_type'] = 'error'
        result['error']    = str(e)[:120]

    return result


# ── Attachment status ──────────────────────────────────────────────────────────

def get_attachment_status(library: ZoteroLibrary, item: dict) -> dict:
    """
    Returns:
      { 'status': 'stored'|'url_only'|'no_attachment',
        'pdf_path': str|None,
        'url': str|None,
        'attachment_key': str|None,
        'notes': [str, …]   # text content of Zotero note children
      }
    """
    num_children = item.get('meta', {}).get('numChildren', 0)
    item_url     = item.get('data', {}).get('url', '')

    if num_children == 0:
        status = 'url_only' if item_url else 'no_attachment'
        return {'status': status, 'pdf_path': None, 'url': item_url or None,
                'attachment_key': None, 'notes': []}

    try:
        children = library.client.children(item['key'])
    except Exception:
        return {'status': 'error', 'pdf_path': None, 'url': item_url or None,
                'attachment_key': None, 'notes': []}

    # Collect note children (Zotero annotations / research notes)
    notes = []
    for child in (children or []):
        if child['data'].get('itemType') == 'note':
            note_text = _strip_html(child['data'].get('note', ''))
            if note_text:
                notes.append(note_text)

    for child in (children or []):
        if child['data'].get('itemType') != 'attachment':
            continue

        content_type = child['data'].get('contentType', '')
        if content_type not in ('application/pdf', 'image/png', 'image/jpeg', 'image/tiff'):
            continue

        # Try explicit path
        path_str = child['data'].get('path', '')
        if path_str and path_str.startswith('/') and Path(path_str).exists():
            return {'status': 'stored', 'pdf_path': path_str,
                    'url': item_url or None, 'attachment_key': child['key'],
                    'notes': notes}

        # Try Zotero storage convention
        filename     = child['data'].get('filename', '')
        storage_path = Path.home() / 'Zotero' / 'storage' / child['key'] / filename
        if filename and storage_path.exists():
            return {'status': 'stored', 'pdf_path': str(storage_path),
                    'url': item_url or None, 'attachment_key': child['key'],
                    'notes': notes}

    # Children exist but no local file found
    status = 'url_only' if item_url else 'attachment_missing'
    return {'status': status, 'pdf_path': None, 'url': item_url or None,
            'attachment_key': None, 'notes': notes}


# ── Cross-reference with extraction results ────────────────────────────────────

def load_download_results(path: Path) -> dict:
    """Load download_results.json keyed by item key."""
    if not path.exists():
        return {}
    try:
        with open(path, encoding='utf-8') as f:
            data = json.load(f)
        return {r['key']: r for r in data if r.get('status') == 'ok' and r.get('pdf_path')}
    except Exception:
        return {}


def load_extraction_results(path: Path) -> dict:
    """Load test_results.json keyed by item_key."""
    if not path.exists():
        return {}
    try:
        with open(path, encoding='utf-8') as f:
            data = json.load(f)
        return {r['item_key']: r for r in data if isinstance(r, dict)}
    except Exception:
        return {}


# ── Main inventory loop ────────────────────────────────────────────────────────

def build_inventory(classify: bool = True) -> list:
    library = ZoteroLibrary()
    print("Fetching items from Zotero...", flush=True)
    items = library.get_all_items()
    print(f"  {len(items)} items found\n")

    extraction = load_extraction_results(_ROOT / 'data' / 'test_results.json')
    downloads  = load_download_results(_ROOT / 'data' / 'download_results.json')

    inventory = []
    n = len(items)

    for idx, item in enumerate(items, 1):
        data    = item.get('data', {})
        key     = item.get('key', '')
        title   = data.get('title', 'Untitled')
        date    = data.get('date', '')
        year    = date[:4] if date else ''
        itype   = data.get('itemType', '')
        url     = data.get('url', '')

        creators  = data.get('creators', [])
        authors   = '; '.join(
            c.get('lastName', c.get('name', ''))
            for c in creators
            if c.get('creatorType') in ('author', 'editor')
        )[:80]
        place     = data.get('place', '')          # place of publication (books)
        publisher = data.get('publisher', '')       # publisher name
        abstract  = data.get('abstractNote', '')    # Zotero abstract field

        # Publication/container title varies by item type
        pub_title = (
            data.get('bookTitle', '')          or  # bookSection
            data.get('publicationTitle', '')   or  # journalArticle, magazineArticle
            data.get('proceedingsTitle', '')   or  # conferencePaper
            data.get('encyclopediaTitle', '')  or  # encyclopediaArticle
            data.get('university', '')         or  # thesis
            data.get('institution', '')        or  # report
            ''
        )

        # Page range for articles / book chapters (e.g. "83-121")
        pages = data.get('pages', '')   # Zotero 'pages' field

        # Tags: list of tag name strings
        tags = [t.get('tag', '') for t in data.get('tags', []) if t.get('tag')]

        print(f"\r  [{idx:3d}/{n}] {title[:55]:<55}", end="", flush=True)

        att = get_attachment_status(library, item)
        pdf_path = att['pdf_path']

        # Fall back to locally downloaded file if Zotero has no attachment
        if not pdf_path and key in downloads:
            dl_path = downloads[key].get('pdf_path')
            if dl_path and Path(dl_path).exists():
                pdf_path = dl_path
                att['status'] = 'downloaded'

        pdf_info = {}
        if classify and pdf_path and att['status'] in ('stored', 'downloaded'):
            pdf_info = classify_pdf(Path(pdf_path))

        ext = extraction.get(key, {})
        quality  = ext.get('quality', {})
        rec      = quality.get('recommendation', '')
        score    = quality.get('score')

        entry = {
            'key':         key,
            'title':       title,
            'year':        year,
            'authors':     authors,
            'item_type':   itype,
            'place':       place,
            'publisher':   publisher,
            'abstract':    abstract or None,
            'pub_title':   pub_title or None,
            'pages':       pages or None,
            'url':         url or att.get('url', ''),
            # Attachment
            'pdf_status':  att['status'],
            'pdf_path':    pdf_path,
            # Classification
            'doc_type':    pdf_info.get('doc_type', 'unknown' if not pdf_path else 'unknown'),
            'page_count':  pdf_info.get('page_count'),
            'avg_chars_pg': pdf_info.get('avg_chars_page'),
            'language':    pdf_info.get('language'),
            # Extraction
            'extracted':   bool(ext),
            'quality_score': round(score, 2) if score is not None else None,
            'recommendation': rec,
            # Zotero metadata
            'tags':        tags,
            'notes':       att.get('notes', []),
        }
        inventory.append(entry)

    print(f"\r  Done — {n} items inventoried.{' '*30}")
    return inventory




# ── Entry point ────────────────────────────────────────────────────────────────

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--output',      default='data/inventory.json')
    parser.add_argument('--no-classify', action='store_true',
                        help='Skip PDF classification (fast mode — no doc_type/language)')
    args = parser.parse_args()

    inv_path  = _ROOT / args.output

    classify = not args.no_classify
    if not _PDFIUM and classify:
        print("⚠ pypdfium2 not available — running in fast mode (no PDF classification)")
        classify = False

    inventory = build_inventory(classify=classify)

    # Save JSON
    inv_path.parent.mkdir(parents=True, exist_ok=True)
    with open(inv_path, 'w', encoding='utf-8') as f:
        json.dump(inventory, f, indent=2, ensure_ascii=False)
    print(f"✓ Inventory saved → {inv_path}")

    # Quick summary
    total    = len(inventory)
    stored   = sum(1 for r in inventory if r['pdf_status'] == 'stored')
    url_only = sum(1 for r in inventory if r['pdf_status'] == 'url_only')
    embedded = sum(1 for r in inventory if r['doc_type'] == 'embedded')
    scanned  = sum(1 for r in inventory if r['doc_type'] == 'scanned')

    print(f"\nSummary:")
    print(f"  Total items:    {total}")
    print(f"  PDF stored:     {stored}")
    print(f"  URL only:       {url_only}")
    print(f"  No attachment:  {total - stored - url_only}")
    print(f"  Embedded fonts: {embedded}")
    print(f"  Scanned:        {scanned}")
    print(f"  Unknown:        {total - embedded - scanned}")


if __name__ == '__main__':
    main()
